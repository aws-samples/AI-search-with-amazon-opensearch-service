{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59189659",
   "metadata": {},
   "source": [
    "# Multimodal Search with Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e8f9b",
   "metadata": {},
   "source": [
    "**Welcome to Multi-Modal search notebook. Use this notebook to build a Multi-Modal Search application powered by Amazon OpenSearch Service**\n",
    "\n",
    "In this notebook, you will perform the following steps in sequence,\n",
    "\n",
    "The lab includes the following steps:\n",
    "1. [Step 1: Get the Cloudformation outputs](#Step-1:-Get-the-Cloudformation-outputs)\n",
    "2. [Step 2: Create the OpenSearch-Bedrock ML connector](#Step-2:-Create-the-OpenSearch-Sagemaker-ML-connector)\n",
    "3. [Step 3: Register and deploy the embedding model in OpenSearch](#Step-3:-Register-and-deploy-the-embedding-model-in-OpenSearch)\n",
    "4. [Step 4: Create the OpenSearch ingest pipeline with text-image-embedding processor](#TODO-Step-4:-Create-the-OpenSearch-ingest-pipeline-with-text-embedding-processor)\n",
    "5. [Step 5: Create the k-NN index](#Step-5:-Create-the-k-NN-index)\n",
    "6. [Step 6: Prepare the image dataset](#Step-6:-Prepare-the-image-dataset)\n",
    "7. [Step 7: Ingest the prepared data into OpenSearch](#Step-7:-Ingest-the-prepared-data-into-OpenSearch)\n",
    "8. [Step 8: Update the environment variables of lambda](#Step-8:-Update-the-environment-variables-of-lambda)\n",
    "9. [Step 9: Create the Lambda URL](#Step-9:-Create-the-Lambda-URL)\n",
    "10. [Step 10: Host the Multi-Modal Search application in EC2](#Step-7:-Host-the-Multi-Modal-Search-application-in-EC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94978bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Install dependencies\n",
    "#Implement header-based authentication and request authentication for AWS services that support AWS auth v4\n",
    "%pip install requests_aws4auth\n",
    "#OpenSearch Python SDK\n",
    "%pip install opensearch_py\n",
    "#Progress bar for for loop\n",
    "%pip install alive-progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8edb7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import sagemaker, boto3, json, time\n",
    "import os\n",
    "from sagemaker.session import Session\n",
    "import subprocess\n",
    "from IPython.utils import io\n",
    "from ruamel.yaml import YAML\n",
    "import io\n",
    "from PIL import Image\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from alive_progress import alive_bar\n",
    "import base64\n",
    "import urllib\n",
    "import boto3\n",
    "import requests \n",
    "from requests_aws4auth import AWS4Auth\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb0cb0",
   "metadata": {},
   "source": [
    "## Step 1: Get the Cloudformation outputs\n",
    "\n",
    "Here, we retrieve the services that are already deployed as a part of the cloudformation template to be used in building the application. The services include,\n",
    "1. **Sagemaker Endpoint**\n",
    "2. **OpenSearch Domain** Endpoint\n",
    "3. **S3** Bucket name\n",
    "4. **Lambda** Function name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b45f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "response = cfn.list_stacks(StackStatusFilter=['CREATE_COMPLETE','UPDATE_COMPLETE'])\n",
    "\n",
    "for cfns in response['StackSummaries']:\n",
    "    if('TemplateDescription' in cfns.keys()):\n",
    "        if('hybrid search' in cfns['TemplateDescription']):\n",
    "            stackname = cfns['StackName']\n",
    "stackname\n",
    "\n",
    "response = cfn.describe_stack_resources(\n",
    "    StackName=stackname\n",
    ")\n",
    "# for resource in response['StackResources']:\n",
    "#     if(resource['ResourceType'] == \"AWS::SageMaker::Endpoint\"):\n",
    "#         SagemakerEmbeddingEndpoint = resource['PhysicalResourceId']\n",
    "\n",
    "cfn_outputs = cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']\n",
    "\n",
    "for output in cfn_outputs:\n",
    "    if('OpenSearchDomainEndpoint' in output['OutputKey']):\n",
    "        OpenSearchDomainEndpoint = output['OutputValue']\n",
    "        \n",
    "    if('EmbeddingEndpointName' in output['OutputKey']):\n",
    "        SagemakerEmbeddingEndpoint = output['OutputValue']\n",
    "        \n",
    "    if('s3' in output['OutputKey'].lower()):\n",
    "        s3_bucket = output['OutputValue']\n",
    "        \n",
    "    if('lambdafunction' in output['OutputKey'].lower()):\n",
    "        lambdaFunction = output['OutputValue']\n",
    "\n",
    "region = boto3.Session().region_name  \n",
    "        \n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "\n",
    "\n",
    "print(\"stackname: \"+stackname)\n",
    "print(\"account_id: \"+account_id)  \n",
    "print(\"region: \"+region)\n",
    "print(\"SagemakerEmbeddingEndpoint: \"+SagemakerEmbeddingEndpoint)\n",
    "print(\"OpenSearchDomainEndpoint: \"+OpenSearchDomainEndpoint)\n",
    "print(\"S3 Bucket: \"+s3_bucket)\n",
    "print(\"lambda Function : \"+lambdaFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c006009",
   "metadata": {},
   "source": [
    "## Step 2: Create the OpenSearch-Bedrock ML connector "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d252adc",
   "metadata": {},
   "source": [
    "Amazon OpenSearch Service AI connectors allows you to create a connector from OpenSearch Service to Bedrock Runtime.\n",
    "To create a connector, we use the Amazon OpenSearch Domain endpoint, BedrockEndpoint for [amazon.titan-embed-image-v1](https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-titan-multimodal-embeddings-model-bedrock/) model and an IAM role that grants OpenSearch Service access to invoke the bedrock model (this role is already created as a part of the cloudformation template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "082606d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup OpenSearch connection\n",
    "host = 'https://'+OpenSearchDomainEndpoint+'/'\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register repository\n",
    "path = '_plugins/_ml/connectors/_create'\n",
    "url = host + path\n",
    "\n",
    "payload = {\n",
    "   \"name\": \"sagemaker: embedding\",\n",
    "   \"description\": \"Test connector for Sagemaker embedding model\",\n",
    "   \"version\": 1,\n",
    "   \"protocol\": \"aws_sigv4\",\n",
    "   \"credential\": {\n",
    "      \"roleArn\": \"arn:aws:iam::\"+account_id+\":role/opensearch-sagemaker-role\"\n",
    "   },\n",
    "   \"parameters\": {\n",
    "      \"region\": region,\n",
    "      \"service_name\": \"bedrock\"\n",
    "   },\n",
    "   \"actions\": [\n",
    "      {\n",
    "         \"action_type\": \"predict\",\n",
    "         \"method\": \"POST\",\n",
    "       \"headers\": {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"x-amz-content-sha256\": \"required\"\n",
    "      },\n",
    "         \n",
    "    \"url\": \"https://bedrock-runtime.\"+region+\".amazonaws.com/model/amazon.titan-embed-image-v1/invoke\",\n",
    "     \"request_body\": \"{ \\\"inputText\\\": \\\"${parameters.inputText:-null}\\\", \\\"inputImage\\\": \\\"${parameters.inputImage:-null}\\\" }\",\n",
    "      \"pre_process_function\": \"\\n    StringBuilder parametersBuilder = new StringBuilder(\\\"{\\\");\\n    if (params.text_docs.length > 0 && params.text_docs[0] != null) {\\n      parametersBuilder.append(\\\"\\\\\\\"inputText\\\\\\\":\\\");\\n      parametersBuilder.append(\\\"\\\\\\\"\\\");\\n      parametersBuilder.append(params.text_docs[0]);\\n      parametersBuilder.append(\\\"\\\\\\\"\\\");\\n      \\n      if (params.text_docs.length > 1 && params.text_docs[1] != null) {\\n        parametersBuilder.append(\\\",\\\");\\n      }\\n    }\\n    \\n    \\n    if (params.text_docs.length > 1 && params.text_docs[1] != null) {\\n      parametersBuilder.append(\\\"\\\\\\\"inputImage\\\\\\\":\\\");\\n      parametersBuilder.append(\\\"\\\\\\\"\\\");\\n      parametersBuilder.append(params.text_docs[1]);\\n      parametersBuilder.append(\\\"\\\\\\\"\\\");\\n    }\\n    parametersBuilder.append(\\\"}\\\");\\n    \\n    return  \\\"{\\\" +\\\"\\\\\\\"parameters\\\\\\\":\\\" + parametersBuilder + \\\"}\\\";\",\n",
    "      \"post_process_function\": \"\\n      def name = \\\"sentence_embedding\\\";\\n      def dataType = \\\"FLOAT32\\\";\\n      if (params.embedding == null || params.embedding.length == 0) {\\n          return null;\\n      }\\n      def shape = [params.embedding.length];\\n      def json = \\\"{\\\" +\\n                 \\\"\\\\\\\"name\\\\\\\":\\\\\\\"\\\" + name + \\\"\\\\\\\",\\\" +\\n                 \\\"\\\\\\\"data_type\\\\\\\":\\\\\\\"\\\" + dataType + \\\"\\\\\\\",\\\" +\\n                 \\\"\\\\\\\"shape\\\\\\\":\\\" + shape + \\\",\\\" +\\n                 \\\"\\\\\\\"data\\\\\\\":\\\" + params.embedding +\\n                 \\\"}\\\";\\n      return json;\\n    \"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.post(url, auth=awsauth, json=payload, headers=headers)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "connector_id = json.loads(r.text)[\"connector_id\"]\n",
    "connector_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdb849",
   "metadata": {},
   "source": [
    "## Step 3: Register and deploy the embedding model in OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80c994",
   "metadata": {},
   "source": [
    "Here, Using the connector_id obtained from the previous step, we register and deploy the model in OpenSearch and get a model identifier (model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ed066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "path = '_plugins/_ml/models/_register'\n",
    "url = host + path\n",
    "\n",
    "payload = { \"name\": \"Bedrock Multimodal embeddings model\",\n",
    "    \"function_name\": \"remote\",\n",
    "    \"description\": \"Bedrock Multimodal embeddings model\",\n",
    "    \"connector_id\": connector_id}\n",
    "\n",
    "r = requests.post(url, auth=awsauth, json=payload, headers=headers)\n",
    "model_id = json.loads(r.text)[\"model_id\"]\n",
    "print(\"Model registered under model_id: \"+model_id)\n",
    "\n",
    "# Deploy the model\n",
    "\n",
    "path = '_plugins/_ml/models/'+model_id+'/_deploy'\n",
    "url = host + path\n",
    "\n",
    "r = requests.post(url, auth=awsauth, headers=headers)\n",
    "deploy_status = json.loads(r.text)[\"status\"]\n",
    "\n",
    "print(\"Deployment status of the model, \"+model_id+\" : \"+deploy_status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e264883",
   "metadata": {},
   "source": [
    "## (Optional) Test the embedding model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec669a",
   "metadata": {},
   "source": [
    "Optional: Run this snippet to test that the OpenSearch-Bedrock connection is successful and you can generate an embedding for text and images. These embeddings produced by the titan image embeddings model are 1024 dimensional, here, we print the first 10 embedding dimensional values of the below sample text/image,\n",
    "\n",
    "**Image_text**: Sleek, stylish black sneakers made for urban exploration. With fashionable looks and comfortable design, these sneakers keep your feet looking great while you walk the city streets in style.\n",
    "\n",
    "**Image**:\n",
    "\n",
    "![Sleek, stylish black sneakers made for urban exploration. With fashionable looks and comfortable design, these sneakers keep your feet looking great while you walk the city streets in style](https://retail-demo-store-us-east-1.s3.amazonaws.com/images/footwear/2d2d8ec8-4806-42a7-b8ba-ceb15c1c7e84.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62c31f69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0025672666, 0.009171144, 0.012386386, -0.020567901, 0.008987624, 0.039484773, 0.051271744, 0.04154323, 0.0230735, -0.031851035]\n",
      "\n",
      "\n",
      "1024 dimensions\n"
     ]
    }
   ],
   "source": [
    "path = '_plugins/_ml/models/'+model_id+'/_predict'\n",
    "url = host + path\n",
    "\n",
    "img_url = \"https://retail-demo-store-us-east-1.s3.amazonaws.com/images/footwear/2d2d8ec8-4806-42a7-b8ba-ceb15c1c7e84.jpg\"\n",
    "img = img_url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(img_url, \"images_retail_amazon/\"+img) #use this for fetching image from url\n",
    "with open(\"images_retail_amazon/\"+img, \"rb\") as image_file:\n",
    "    input_image_binary = base64.b64encode(image_file.read()).decode(\"utf8\")\n",
    "\n",
    "payload = {\n",
    "                  \"parameters\": {\n",
    "                    \"inputText\": \"Sleek, stylish black sneakers made for urban exploration. With fashionable looks and comfortable design, these sneakers keep your feet looking great while you walk the city streets in style\",\n",
    "                      \"inputImage\":input_image_binary\n",
    "                              }\n",
    "                        }\n",
    "r = requests.post(url, auth=awsauth, json=payload, headers=headers)\n",
    "embed = json.loads(r.text)['inference_results'][0]['output'][0]['data'][0:10]\n",
    "shape = json.loads(r.text)['inference_results'][0]['output'][0]['shape'][0]\n",
    "\n",
    "print(str(embed))\n",
    "print(\"\\n\")\n",
    "print(str(shape)+\" dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4fa35",
   "metadata": {},
   "source": [
    "## Step 4: Create the OpenSearch ingest pipeline with text_image_embedding processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd49613",
   "metadata": {},
   "source": [
    "In the ingestion pipeline, you choose \"text_image_embedding\" processor to generate vector embeddings for \"image_description\" field and/or \"image_binary\" field, store vector data in \"vector_embedding\" field of type knn_vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"_ingest/pipeline/bedrock-multimodal-ingest-pipeline\"\n",
    "url = host + path\n",
    "payload = {\n",
    "  \"description\": \"A text/image embedding pipeline\",\n",
    "  \"processors\": [\n",
    "    {\n",
    "      \"text_image_embedding\": {\n",
    "        \"model_id\":'jEvHQYwBuQkLO8mDLE2L',\n",
    "        \"embedding\": \"vector_embedding\",\n",
    "        \"field_map\": {\n",
    "          \"text\": \"image_description\",\n",
    "          \"image\": \"image_binary\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "r = requests.put(url, auth=awsauth, json=payload, headers=headers)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e204695",
   "metadata": {},
   "source": [
    "## Step 5: Create the k-NN index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f21a9f",
   "metadata": {},
   "source": [
    "Create the K-NN index and set the pipeline created in the previous step \"bedrock-multimodal-ingest-pipeline\" as the default pipeline. The vector_embedding field must be mapped as a k-NN vector with 1024 dimensions matching the bedrock model dimension. \n",
    "\n",
    "For the kNN index we use **nmslib** engine with **hnsw** algorithm and **l2** spacetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"bedrock-multimodal-demostore-search-index\"\n",
    "url = host + path\n",
    "\n",
    "#this will delete the index if already exists\n",
    "requests.delete(url, auth=awsauth, json=payload, headers=headers)\n",
    "\n",
    "payload = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True,\n",
    "    \"default_pipeline\": \"bedrock-multimodal-ingest-pipeline\",\n",
    "    \"number_of_shards\": 4,\n",
    "    \"number_of_replicas\": \"0\"\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"vector_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": shape,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"lucene\",\n",
    "          \"parameters\": {}\n",
    "        }\n",
    "      },\n",
    "         \"caption\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "            \"category\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "              \"style\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "                \"price\": {\n",
    "        \"type\": \"double\"\n",
    "      },\n",
    "        \"gender_affinity\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "        \"stock\": {\n",
    "        \"type\": \"integer\"\n",
    "      },\n",
    "      \"image_description\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "        \"image_s3_url\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"image_binary\": {\n",
    "        \"type\": \"binary\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = requests.put(url, auth=awsauth, json=payload, headers=headers)\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269d744",
   "metadata": {},
   "source": [
    "## Step 6: Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9815d45",
   "metadata": {},
   "source": [
    "Download the Demo retail store metadata file from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://retail-demo-store-us-east-1/data/products.yaml .\n",
    "\n",
    "yaml = YAML()\n",
    "input_file = 'products.yaml'\n",
    "\n",
    "items_ = yaml.load(open(input_file))\n",
    "\n",
    "print(json.dumps(items_[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72bcc58",
   "metadata": {},
   "source": [
    "## Step 7: Ingest the prepared data into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb015a",
   "metadata": {},
   "source": [
    "We ingest only the metadata of the product images into the opensearch index using bulk request\n",
    "\n",
    "This step takes approcimately 10 minutes to load the data into opensearch\n",
    "\n",
    "We also resize all the images to have uniform height and width using the below function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(photo, bucket, width, height):\n",
    "    \n",
    "    Image.MAX_IMAGE_PIXELS = 100000000\n",
    "    \n",
    "    with Image.open(photo) as image:\n",
    "        image.verify()\n",
    "    with Image.open(photo) as image:    \n",
    "        \n",
    "        if image.format in [\"JPEG\", \"PNG\"]:\n",
    "            file_type = image.format.lower()\n",
    "            path = image.filename.rsplit(\".\", 1)[0]\n",
    "\n",
    "            image.thumbnail((width, height))\n",
    "            image.save(f\"{path}-resized.{file_type}\")\n",
    "\n",
    "            #fileshort = os.path.basename(path)\n",
    "            \n",
    "            #print(path)\n",
    "\n",
    "            s3.upload_file(\n",
    "                f\"{path}-resized.{file_type}\",\n",
    "                bucket,\n",
    "                f\"resized/{fileshort}-resized.{file_type}\",\n",
    "                ExtraArgs={\"ContentType\": f\"image/{file_type}\"},\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Unsupported image format\")\n",
    "        \n",
    "    return file_type, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f637347",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "host = 'https://'+OpenSearchDomainEndpoint+'/'\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "headers = { \"Content-Type\": \"application/json\"}\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': OpenSearchDomainEndpoint, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")\n",
    "\n",
    "#restrict the data to 50 images\n",
    "#items_ = items_[0:50]\n",
    "\n",
    "cnt = 0\n",
    "batch = 0\n",
    "action = json.dumps({ \"index\": { \"_index\": \"bedrock-multimodal-demostore-search-index\" } })\n",
    "body_ = ''\n",
    "batch_size = 100\n",
    "last_batch = int(len(items_)/batch_size)\n",
    "width = 2048\n",
    "height = 2048\n",
    "\n",
    "\n",
    "with alive_bar(len(items_), force_tty = True) as bar:\n",
    "    for item in items_:\n",
    "        cnt = cnt +1\n",
    "          \n",
    "        payload = {}\n",
    "        payload['image_s3_url'] = \"https://retail-demo-store-us-east-1.s3.amazonaws.com/images/\"+item[\"category\"]+\"/\"+item[\"image\"]\n",
    "        payload['image_description'] = item['description']\n",
    "        payload['price'] = item['price']\n",
    "        \n",
    "        if('style' in item):\n",
    "            payload['style'] = item['style']\n",
    "        payload['category'] = item['category']\n",
    "        if('current_stock' in item):\n",
    "            payload['current_stock'] = item['current_stock']\n",
    "        if('gender_affinity' in item):\n",
    "            payload['gender_affinity'] = item['gender_affinity']\n",
    "        payload['caption'] = item['name']\n",
    "        \n",
    "        #generate image binary\n",
    "        \n",
    "        fileshort = \"images_retail_amazon/\"+item[\"image\"]\n",
    "\n",
    "        s3.download_file('retail-demo-store-us-east-1', \"images/\"+item[\"category\"]+\"/\"+item[\"image\"], fileshort)\n",
    "\n",
    "\n",
    "\n",
    "        file_type, path = resize_image(fileshort, s3_bucket, width, height)\n",
    "\n",
    "        with open(fileshort.split(\".\")[0]+\"-resized.\"+file_type, \"rb\") as image_file:\n",
    "            input_image = base64.b64encode(image_file.read()).decode(\"utf8\")\n",
    "        \n",
    "        os.remove(fileshort.split(\".\")[0]+\"-resized.\"+file_type)\n",
    "        os.remove(fileshort)\n",
    "\n",
    "        payload['image_binary'] = input_image\n",
    "        \n",
    "        body_ = body_ + action + \"\\n\" + json.dumps(payload) + \"\\n\"\n",
    "        \n",
    "        if(cnt == batch_size):\n",
    "            \n",
    "            response = client.bulk(\n",
    "            index = 'bedrock-multimodal-demostore-search-index',\n",
    "            body = body_\n",
    "            )\n",
    "            \n",
    "            cnt = 0\n",
    "            batch += 1\n",
    "            \n",
    "            if(batch != last_batch):\n",
    "                body_ = ''\n",
    "        \n",
    "        \n",
    "        bar()\n",
    "    #ingest the remaining rows\n",
    "    response = client.bulk(\n",
    "            index = 'bedrock-multimodal-demostore-search-index',\n",
    "            body = body_\n",
    "            )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f39448",
   "metadata": {},
   "source": [
    "## Step 8: Update the environment variables of lambda\n",
    "\n",
    "Here, we pass the OpenSearch bedrock model identifier to Lambda so that the the incoming queries will be embedded using the same model we used to embed the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c557766",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "exist_env = lambda_client.get_function_configuration(FunctionName=lambdaFunction)['Environment']['Variables']\n",
    "\n",
    "if('BEDROCK_MULTIMODAL_MODEL_ID' in exist_env.keys()):\n",
    "    exist_env.update({'BEDROCK_MULTIMODAL_MODEL_ID': model_id})\n",
    "else:\n",
    "    exist_env['BEDROCK_MULTIMODAL_MODEL_ID'] = model_id\n",
    "\n",
    "\n",
    "response = lambda_client.update_function_configuration(\n",
    "            FunctionName=lambdaFunction,\n",
    "            Environment={\n",
    "                'Variables': exist_env\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18947159",
   "metadata": {},
   "source": [
    "## Step 9: Create the Lambda URL\n",
    "\n",
    "Here we create external Lambda URL for lambda function to be called from the outside world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a97269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bwwj5hqbym7w245urmrijqrifa0gzmoc.lambda-url.us-east-1.on.aws/\n"
     ]
    }
   ],
   "source": [
    "lambda_ = boto3.client('lambda')\n",
    "\n",
    "try:\n",
    "  response = lambda_.get_function_url_config(FunctionName=lambdaFunction)\n",
    "\n",
    "except lambda_.exceptions.ResourceNotFoundException:\n",
    "    response_ = lambda_.add_permission(\n",
    "    FunctionName=lambdaFunction,\n",
    "    StatementId=lambdaFunction+'_permissions',\n",
    "    Action=\"lambda:InvokeFunctionUrl\",\n",
    "    Principal=account_id,\n",
    "    FunctionUrlAuthType='AWS_IAM')\n",
    "\n",
    "\n",
    "    response = lambda_.create_function_url_config(\n",
    "    FunctionName=lambdaFunction,\n",
    "    AuthType='AWS_IAM',\n",
    "    Cors={\n",
    "        'AllowCredentials': True,\n",
    "\n",
    "        'AllowMethods':[\"*\"],\n",
    "        'AllowOrigins': [\"*\"]\n",
    "\n",
    "    },\n",
    "    InvokeMode='RESPONSE_STREAM'\n",
    "    )\n",
    "\n",
    "query_invoke_URL = response['FunctionUrl']\n",
    "print(query_invoke_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1154fad",
   "metadata": {},
   "source": [
    "## Step 10: Host the Hybrid Search application in EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b857dea",
   "metadata": {},
   "source": [
    "## Notice\n",
    "\n",
    "To ensure security access to the provisioned resources, we use EC2 security group to limit access scope. Before you go into the final step, you need to add your current **PUBLIC IP** address to the ec2 security group so that you are able to access the web application (chat interface) that you are going to host in the next step.\n",
    "\n",
    "<h3 style=\"color:red;\"><U>Warning</U></h3>\n",
    "<h4>Without doing the below steps, you will not be able to proceed further.</h4>\n",
    "\n",
    "<div>\n",
    "    <h3 style=\"color:red;\"><U>Enter your IP address </U></h3>\n",
    "    <h4> STEP 1. Get your IP address <span style=\"display:inline;color:blue\"><a href = \"https://ipinfo.io/ip \">HERE</a></span>. If you are connecting with VPN, we recommend you disconnect VPN first.</h4>\n",
    "</div>\n",
    "\n",
    "<h4>STEP 2. Run the below cell </h4>\n",
    "<h4>STEP 3. Paste the IP address in the input box that prompts you to enter your IP</h4>\n",
    "<h4>STEP 4. Press ENTER</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ip = (input(\"Enter your IP : \")).split(\".\")\n",
    "my_ip.pop()\n",
    "IP = \".\".join(my_ip)+\".0/24\"\n",
    "\n",
    "port_protocol = {443:'HTTPS',80:'HTTP',8501:'streamlit'}\n",
    "\n",
    "IpPermissions = []\n",
    "\n",
    "for port in port_protocol.keys():\n",
    "     IpPermissions.append({\n",
    "            'FromPort': port,\n",
    "            'IpProtocol': 'tcp',\n",
    "            'IpRanges': [\n",
    "                {\n",
    "                    'CidrIp': IP,\n",
    "                    'Description': port_protocol[port]+' access',\n",
    "                },\n",
    "            ],\n",
    "            'ToPort': port,\n",
    "        })\n",
    "\n",
    "IpPermissions\n",
    "\n",
    "for output in cfn_outputs:\n",
    "    if('securitygroupid' in output['OutputKey'].lower()):\n",
    "        sg_id = output['OutputValue']\n",
    "        \n",
    "#sg_id = 'sg-0e0d72baa90696638'\n",
    "\n",
    "ec2_ = boto3.client('ec2')        \n",
    "\n",
    "response = ec2_.authorize_security_group_ingress(\n",
    "    GroupId=sg_id,\n",
    "    IpPermissions=IpPermissions,\n",
    ")\n",
    "\n",
    "print(\"\\nIngress rules added for the security group, ports:protocol - \"+json.dumps(port_protocol)+\" with my ip - \"+IP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e4328",
   "metadata": {},
   "source": [
    "Finally, We are ready to host our conversational search application, here we perform the following steps, Steps 2-5 are achieved by executing the terminal commands in the ec2 instance using a SSM client.\n",
    "1. Update the web application code files with lambda url (in [api.py](https://github.com/aws-samples/semantic-search-with-amazon-opensearch/blob/main/generative-ai/Module_1_Build_Conversational_Search/webapp/api.py)) and s3 bucket name (in [app.py](https://github.com/aws-samples/semantic-search-with-amazon-opensearch/blob/main/generative-ai/Module_1_Build_Conversational_Search/webapp/app.py))\n",
    "2. Archieve the application files and push to the configured s3 bucket.\n",
    "3. Download the application (.zip) from s3 bucket into ec2 instance (/home/ec2-user/), and uncompress it.\n",
    "4. We install the streamlit and boto3 dependencies inside a virtual environment inside the ec2 instance.\n",
    "5. Start the streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc79d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: api.py (deflated 58%)\n",
      "updating: app.py (deflated 75%)\n",
      "upload: webapp/webapp.zip to s3://hybridsearch-opensearch-app-s3buckethosting-b7nfsjknlc83/webapp.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i-05bbd71645c0b0990'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modify the code files with lambda url and s3 bucket names\n",
    "query_invoke_URL_cmd = query_invoke_URL.replace(\"/\",\"\\/\")\n",
    "\n",
    "#Update the webapp files to include the s3 bucket name and the LambdaURL\n",
    "!sed -i 's/API_URL_TO_BE_REPLACED/{query_invoke_URL_cmd}/g' webapp/api.py\n",
    "#Push the WebAPP code artefacts to s3\n",
    "!cd webapp && zip -r webapp.zip *\n",
    "!aws s3 cp webapp/webapp.zip s3://$s3_bucket\n",
    "        \n",
    "#Get the Ec2 instance ID which is already deployed\n",
    "response = cfn.describe_stack_resources(\n",
    "    StackName=stackname\n",
    ")\n",
    "for resource in response['StackResources']:\n",
    "    if(resource['ResourceType'] == 'AWS::EC2::Instance'):\n",
    "        ec2_instance_id = resource['PhysicalResourceId']\n",
    "   \n",
    "ec2_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1351e",
   "metadata": {},
   "source": [
    "Copy the URL that will be generated after running the next cell and open the URL in your web browser to start using the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "70e2339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait while the application is being hosted . . .\n",
      "\n",
      "Application hosted successfully\n",
      "\n",
      "Click the below URL to open the application. It may take up to a minute or two to start the application, Please keep refreshing the page if you are seeing connection error.\n",
      "\n",
      "http://44.204.151.62:8501\n"
     ]
    }
   ],
   "source": [
    "# function to execute commands in ec2 terminal\n",
    "def execute_commands_on_linux_instances(client, commands):\n",
    "    resp = client.send_command(\n",
    "        DocumentName=\"AWS-RunShellScript\", # One of AWS' preconfigured documents\n",
    "        Parameters={'commands': commands},\n",
    "        InstanceIds=[ec2_instance_id],\n",
    "    )\n",
    "    return resp['Command']['CommandId']\n",
    "\n",
    "ssm_client = boto3.client('ssm') \n",
    "\n",
    "commands = [\n",
    "            'aws s3 cp s3://'+s3_bucket+'/webapp.zip /home/ec2-user/',\n",
    "            'unzip -o /home/ec2-user/webapp.zip -d /home/ec2-user/'  ,  \n",
    "            'sudo chmod -R 0777 /home/ec2-user/',\n",
    "            'python3 -m venv /home/ec2-user/.myenv',\n",
    "            'source /home/ec2-user/.myenv/bin/activate',\n",
    "            'pip install streamlit',\n",
    "            'pip install boto3',\n",
    "    \n",
    "            #start the web applicaiton\n",
    "            'streamlit run /home/ec2-user/app.py',\n",
    "            ]\n",
    "\n",
    "command_id = execute_commands_on_linux_instances(ssm_client, commands)\n",
    "\n",
    "ec2_ = boto3.client('ec2')\n",
    "response = ec2_.describe_instances(\n",
    "    InstanceIds=[ec2_instance_id]\n",
    ")\n",
    "public_ip = response['Reservations'][0]['Instances'][0]['PublicIpAddress']\n",
    "print(\"Please wait while the application is being hosted . . .\")\n",
    "time.sleep(10)\n",
    "print(\"\\nApplication hosted successfully\")\n",
    "print(\"\\nClick the below URL to open the application. It may take up to a minute or two to start the application, Please keep refreshing the page if you are seeing connection error.\\n\")\n",
    "print('http://'+public_ip+\":8501\")\n",
    "#print(\"\\nCheck the below video on how to interact with the application\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4115439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
