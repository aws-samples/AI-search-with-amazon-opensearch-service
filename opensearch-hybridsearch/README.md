## Hybrid Search with OpenSearch





**Overview of Hands-on Labs**

1. Train a Sentence Transformer BERT model using Amazon SageMaker to fine tune the pre-trained BERT embeddings on data retrieval task
2. Deploy the fine-tuned BERT model on Amazon SageMaker for both real-time and batch inference.
3. Use Amazon OpenSearch service to index andd store the sentence embeddings and perform realtime search against query

**References**
- [1]  “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding“, Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova.
- [2]  Reimers, N., & Gurevych, I. (2019). Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084.



## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.

